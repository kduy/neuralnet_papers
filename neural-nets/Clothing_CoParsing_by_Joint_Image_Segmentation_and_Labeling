# Paper

* **Title**: Clothing Co-Parsing by Joint Image Segmentation and Labeling
* **Authors**: Wei Yang1, Ping Luo2, Liang Lin
* **Link**: https://arxiv.org/pdf/1502.00739.pdf

# Summary
* What
  * This paper aims at developing an integrated system of clothing co-parsing, in order to jointly parse a set of clothing images (unsegmented but annotated with tags) into semantic configurations
  * Propose a data-driven framework consisting of two phases of inference:
    + image co-segmentation
    + region co-labeling
  * Achieve 90.29% / 88.23% segmentation accuracy and 65.52% / 63.89% recognition rate on the Fashionista and the CCP dataset
 
 * How
   * They build a system consisting 2 sequential phases of inference over a set of colthing images:
    + image co-segmentation for extracting distinguishable clothes regions
    + region co-labeling for recognizing various garment items
   * Furthermore, they exploit contexts of clothing configuration, e.g., spatial locations and mutual relations of clothes items, inspired by the successes of object/scene context modeling
   
   ** Co-segmentation
   


